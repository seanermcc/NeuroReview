---
date: '2019-09-14'
episode_title: Francois Chollet
guest: Francois Chollet
id: lex_38
pod_host: Lex
pod_length: 2
pod_notes: Taking on Intelligence
pod_num: 38
rating: 8.9
title: 'Lex #38'
categories:
- Computer Science
- Vision
- Deep Learning
- Intelligence
- AI Safety
- AI
Youtube LInk: https://www.youtube.com/watch?v=Bo8MY4JpiXE
Youtube ID: Bo8MY4JpiXE
Pod_Points: 17.8
num_views: 193252
num_likes: 3795
num_comments: 198
days_online: 2181
view_density: 88.61
view_density_weekly: 620
---








Another great episode - I could listen to him talk all day for the accent alone if I'm being honest. But I feel this was a very insightful interview with someone who has a lot of intelligence in this very theoretical space. His primary take is that intelligence is defined as how well something is to adapt to new input that it has not seen before (to learn) - arguing that the human who created the program is the one with the intelligence. Lots of great philosophical and abstract discussion that prompts a lot of thought around AI/ML/life. He does a great job of appealing to computer science constructs when describing what we know about the brain, the “mind” & human cognition, etc..

Hearing this, I’m curious about his take on the current LLMs (circa GPT3 in 2024/5-ish) in regard to their intelligence. As I understand, they wouldn’t fall under “intelligent systems” given they are trained on fixed data created by humans. 


Reply:
    -TK